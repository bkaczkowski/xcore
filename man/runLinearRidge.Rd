% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/stats.R
\name{runLinearRidge}
\alias{runLinearRidge}
\title{Linear ridge regression}
\usage{
runLinearRidge(x, y, offset, alpha = 0, standardize = TRUE, ...)
}
\arguments{
\item{x}{\code{x} matrix as in \code{glmnet}.}

\item{y}{response \code{y} as in \code{glmnet}.}

\item{offset}{Offset vector (matrix) as in \code{glmnet}}

\item{alpha}{The elasticnet mixing parameter, with \eqn{0\le\alpha\le 1}.
The penalty is defined as
\deqn{(1-\alpha)/2||\beta||_2^2+\alpha||\beta||_1.} \code{alpha=1} is the
lasso penalty, and \code{alpha=0} the ridge penalty.}

\item{standardize}{Logical flag for x variable standardization, prior to
fitting the model sequence. The coefficients are always returned on the
original scale. Default is \code{standardize=TRUE}.  If variables are in the
same units already, you might not wish to standardize. See details below for
y standardization with \code{family="gaussian"}.}

\item{...}{Other arguments that can be passed to \code{glmnet}}
}
\value{
an object of class "cv.glmnet" is returned. See
\code{\link[glmnet]{cv.glmnet}} for more details.
}
\description{
Wrapper around \code{\link[glmnet]{cv.glmnet}} to run linear ridge regression
with lambda selection using cross-validation.
}
